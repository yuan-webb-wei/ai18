{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cart Pole With an Explicit Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explicit policy used in this cart pole problem is described below: <br />\n",
    "In each state, examine the direction of pole angle and the direction of pole velocity: if they are both negative, push cart towards left; if they are both positive, push cart towards right; otherwise, examine the direction of cart position and cart velocity: if their product value is positive (meaning cart velocity follows the direction of cart position), push cart towards the opposite direction of cart position; otherwise push cart towards the opposite direction of cart velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cart pole environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "# goal: prevent cart from falling over (-2.4 < cart_position < 2.4 and -12 degree < pole_angle < 12 degree) for 200 episodes\n",
    "# action: 0 (push cart towards left), 1 (push cart towards right)\n",
    "# observation (state): [cart_position (range: [-4.8, 4.8]), cart_velocity (range: [-Inf, Inf]), pole_angle (range: [-24 degree, 24 degree]), pole_velocity_at_tip (range: [-Inf, Inf])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode():\n",
    "    total_reward = 0\n",
    "    time_step = 0\n",
    "    observation = env.reset()\n",
    "    for time_step in range(200):\n",
    "        env.render()\n",
    "        # get cart position, cart velocity, pole angle, and pole velocity at tip from observation (state)\n",
    "        cart_position, cart_velocity, pole_angle, pole_velocity_at_tip = observation\n",
    "        # apply an explicit policy\n",
    "        if pole_angle < 0 and pole_velocity_at_tip < 0:\n",
    "            action = 0\n",
    "        elif pole_angle > 0 and pole_velocity_at_tip > 0:\n",
    "            action = 1\n",
    "        else:\n",
    "            if cart_position < 0:\n",
    "                if cart_velocity < 0:\n",
    "                    action = 1\n",
    "                else:\n",
    "                    action = 0\n",
    "            else:\n",
    "                if cart_velocity > 0:\n",
    "                    action = 0\n",
    "                else:\n",
    "                    action = 1\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward, time_step + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Reward:150.00, Timestep:150\n",
      "Episode: 1, Reward:200.00, Timestep:200\n",
      "Episode: 2, Reward:200.00, Timestep:200\n",
      "Episode: 3, Reward:200.00, Timestep:200\n",
      "Episode: 4, Reward:169.00, Timestep:169\n",
      "Episode: 5, Reward:200.00, Timestep:200\n",
      "Episode: 6, Reward:149.00, Timestep:149\n",
      "Episode: 7, Reward:154.00, Timestep:154\n",
      "Episode: 8, Reward:200.00, Timestep:200\n",
      "Episode: 9, Reward:200.00, Timestep:200\n",
      "Episode:10, Reward:200.00, Timestep:200\n",
      "Episode:11, Reward:200.00, Timestep:200\n",
      "Episode:12, Reward:200.00, Timestep:200\n",
      "Episode:13, Reward:200.00, Timestep:200\n",
      "Episode:14, Reward:200.00, Timestep:200\n",
      "Episode:15, Reward:200.00, Timestep:200\n",
      "Episode:16, Reward:162.00, Timestep:162\n",
      "Episode:17, Reward:200.00, Timestep:200\n",
      "Episode:18, Reward:200.00, Timestep:200\n",
      "Episode:19, Reward:200.00, Timestep:200\n",
      "Over 20 episodes, average reward: 189.2\n"
     ]
    }
   ],
   "source": [
    "# test episode runs\n",
    "all_reward = 0\n",
    "episodes = 20\n",
    "for episode in range(episodes):\n",
    "    total_reward, time_step = run_episode()\n",
    "    all_reward += total_reward\n",
    "    print(f\"Episode:{episode:2d}, Reward:{total_reward:3.2f}, Timestep:{time_step:3d}\")\n",
    "print(f\"Over {episodes} episodes, average reward: {all_reward / episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close cart pole environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
